{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d495a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import importlib\n",
    "from functools import reduce, partial\n",
    "import operator\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import numpy as nnp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import torch\n",
    "# torch.set_default_dtype(torch.float32)\n",
    "# mps_device = torch.device(\"mps\")\n",
    "# torch.set_default_device(mps_device)\n",
    "# from torchinfo import summary\n",
    "\n",
    "import tensorflow as tf\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1af02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# import traceback\n",
    "\n",
    "# warnings.simplefilter(\"error\")\n",
    "# warnings.simplefilter(\"once\", category=qml.PennyLaneDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab1d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "nnp.random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "# torch.manual_seed(42)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c74b30",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334f9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_4(num_images: int, size: int = 4, noise: float = 0.15):\n",
    "    \"\"\"Generate a vertical horizontal left diagonal or right diagonal line on the grid and then add noise in to it\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        # Create a blank image\n",
    "        image = np.zeros((size, size), dtype=np.uint16)\n",
    "        # Randomly choose a line orientation\n",
    "        if np.random.rand() < 0.25:\n",
    "            # Vertical line\n",
    "            x = np.random.randint(0, size)\n",
    "            image[:, x] = 255\n",
    "            labels.append(0)  # Label for vertical line\n",
    "        elif np.random.rand() < 0.5:\n",
    "            # Horizontal line\n",
    "            y = np.random.randint(0, size)\n",
    "            image[y, :] = 255\n",
    "            labels.append(1)\n",
    "        elif np.random.rand() < 0.75:\n",
    "            # Left diagonal line\n",
    "            for j in range(size):\n",
    "                image[j, j] = 255\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            # Right diagonal line\n",
    "            for j in range(size):\n",
    "                image[j, size - j - 1] = 255\n",
    "            labels.append(3)\n",
    "\n",
    "        # Add noise to the image\n",
    "        noise_matrix = np.random.normal(0, noise * 255, (size, size))\n",
    "        image = np.clip(image + noise_matrix, 0.0, 255.0)\n",
    "        images.append(image.astype(np.float32) / 255.0)\n",
    "\n",
    "    # one hot encode the labels\n",
    "    labels = np.array(labels)\n",
    "    labels = ((-1 * np.ones((4,4))) + (2 * np.eye(4)))[labels]\n",
    "    return nnp.array(images), nnp.array(labels).astype(nnp.float32)\n",
    "\n",
    "def generate_dataset_2(num_images: int, size: int = 4, noise: float = 0.15):\n",
    "    \"\"\"Generate a vertical or horizontal line on the grid and then add noise in to it\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        # Create a blank image\n",
    "        image = np.zeros((size, size), dtype=np.uint16)\n",
    "        # Randomly choose a line orientation\n",
    "        if np.random.rand() < 0.5:\n",
    "            # Vertical line\n",
    "            x = np.random.randint(0, size)\n",
    "            image[:, x] = 255\n",
    "            labels.append(-1.0)  # Label for vertical line\n",
    "        else:\n",
    "            # Horizontal line\n",
    "            y = np.random.randint(0, size)\n",
    "            image[y, :] = 255\n",
    "            labels.append(1.0)\n",
    "\n",
    "        # Add noise to the image\n",
    "        noise_matrix = np.random.normal(0, noise * 255, (size, size))\n",
    "        image = np.clip(image + noise_matrix, 0.0, 255.0)\n",
    "        images.append(image.astype(np.float32) / 255.0)\n",
    "\n",
    "    # one hot encode the labels\n",
    "    # labels = np.array(labels)\n",
    "    # labels = np.eye(2)[labels]\n",
    "    return nnp.array(images), nnp.array(labels).astype(nnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43399685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = generate_dataset_2(120, noise=0.1)\n",
    "\n",
    "# Split the data\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "# NOTE: Pennylane will freak out if the number of training images is not divisible by the batch size\n",
    "test_labels.dtype, test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f9a199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(train_images[i].reshape(int(train_images.shape[1]), int(train_images.shape[2])), cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "067ce93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_q, test_images_q = nnp.array([hots_to_sv(img.flatten()) for img in train_images]), nnp.array([hots_to_sv(img.flatten()) for img in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "010162bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 08:03:47.092560: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-05-31 08:03:47.092589: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2025-05-31 08:03:47.092609: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748693027.092628 13099393 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1748693027.092651 13099393 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tf.complex64,\n",
       " tf.float32,\n",
       " tf.complex64,\n",
       " tf.float32,\n",
       " '/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " TensorShape([84, 65536]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_q, train_labels = tf.convert_to_tensor(train_images_q), tf.convert_to_tensor(train_labels)\n",
    "test_images_q, test_labels = tf.convert_to_tensor(test_images_q), tf.convert_to_tensor(test_labels)\n",
    "train_images_q.dtype, train_labels.dtype, test_images_q.dtype, test_labels.dtype, train_images_q.device, train_images_q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6e2eb",
   "metadata": {},
   "source": [
    "# Creating Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ac6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_images_q.shape[1] ** 0.5 % 1 == 0, \"The input image size must be a perfect square\"\n",
    "B = 4\n",
    "N = 4\n",
    "w = N**2 # + B\n",
    "dev = qml.device(\"default.qubit\", wires=w)\n",
    "wire_arr = nnp.arange(N**2, dtype=nnp.int32).reshape(N, N)\n",
    "\n",
    "KERNEL_SIZE = 2\n",
    "KERNEL_LAYERS = 2 # two was working pretty well\n",
    "STRIDE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c24c6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @partial(qml.batch_input, argnums=0) # this is really broken (need to file a pennylane issue)\n",
    "@partial(qml.batch_input, argnum=0)\n",
    "@qml.qnode(dev, interface='tf')\n",
    "def qnode(inputs, \n",
    "          first_kernel, first_pooling, \n",
    "          second_kernel, second_pooling, \n",
    "          # fc_weights, fc_bias\n",
    "):\n",
    "    # Input Layer\n",
    "    # for i, j in itertools.product(range(N), range(N)):\n",
    "    #     qml.RX(1.0 * np.pi * inputs[i, j], wires=wire_arr[i, j])\n",
    "    qml.StatePrep(inputs, wires=wire_arr.flatten(), validate_norm=False)\n",
    "    \n",
    "    # First Convolution Layer    \n",
    "    convolution_pooling_op(first_kernel, first_pooling, wire_arr, STRIDE)\n",
    "    reduced_wire_arr = wire_arr[1::2, 1::2]\n",
    "    \n",
    "    # Second Convolution Layer\n",
    "    convolution_pooling_op(second_kernel, second_pooling, reduced_wire_arr, STRIDE)\n",
    "    reduced_wire_arr = reduced_wire_arr[1::2, 1::2]\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    # fully_connected_op(fc_weights, fc_bias, reduced_wire_arr.flatten().tolist(), list(range(N*N, N*N + B)))\n",
    "    \n",
    "    # Measurement\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in reduced_wire_arr.flatten().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876abf89",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonhanrattie/Downloads/QuantumBattleship.nosync/.conda/lib/python3.10/site-packages/pennylane/qnn/keras.py:317: PennyLaneDeprecationWarning: The 'KerasLayer' class is deprecated and will be removed in v0.42. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'first_kernel': (8, TensorShape([2, 2, 2])),\n",
       "  'first_pooling': (4, TensorShape([2, 2])),\n",
       "  'second_kernel': (8, TensorShape([2, 2, 2])),\n",
       "  'second_pooling': (4, TensorShape([2, 2]))},\n",
       " <Quantum Keras Layer: func=qnode>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_shapes = {\n",
    "    \"first_kernel\": (KERNEL_LAYERS, KERNEL_SIZE, KERNEL_SIZE),\n",
    "    \"first_pooling\": (KERNEL_SIZE, KERNEL_SIZE),\n",
    "    \"second_kernel\": (KERNEL_LAYERS, KERNEL_SIZE, KERNEL_SIZE),\n",
    "    \"second_pooling\": (KERNEL_SIZE, KERNEL_SIZE),\n",
    "    # \"fc_weights\": (B - 1, B),\n",
    "    # \"fc_bias\": (B,),\n",
    "}\n",
    "\n",
    "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=(1,))\n",
    "{name: (reduce(operator.mul, x.shape), x.shape) for name, x in qlayer.qnode_weights.items()}, qlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60176fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2**(N * N),)),\n",
    "    qlayer,\n",
    "])\n",
    "# model.load_weights('line_model.keras')\n",
    "# model = torch.nn.Sequential(\n",
    "#     qlayer,\n",
    "#     # torch.nn.Lambda(prob_extraction),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f558566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ keras_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">KerasLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ keras_layer (\u001b[38;5;33mKerasLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m24\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "model.compile(opt, loss=\"MSE\", metrics=[custom_accuracy])\n",
    "model.summary()\n",
    "# summary(model, input_data=train_images_q[0:3, :], device=mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b06efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "Sample output shape: (7, 1)\n",
      "Sample output: [[-0.0135442 ]\n",
      " [-0.01799637]\n",
      " [-0.00746002]\n",
      " [ 0.01995109]\n",
      " [-0.00760766]\n",
      " [-0.01380593]\n",
      " [-0.01011737]] tf.Tensor([-1. -1.  1.  1.  1. -1.  1.], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test the forward pass with a batch of training images\n",
    "sample_output = model(train_images_q[21:21+7])  # Pass the first 3 training images\n",
    "print(\"Sample output shape:\", sample_output.shape)\n",
    "print(\"Sample output:\", sample_output.numpy(), train_labels[21:21+7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4e01b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd44fafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([80, 65536]),\n",
       " TensorShape([80]),\n",
       " TensorShape([32, 65536]),\n",
       " TensorShape([32]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "remainder = train_images_q.shape[0] % BATCH_SIZE\n",
    "if remainder != 0:\n",
    "    train_images_q = train_images_q[:-remainder]\n",
    "    train_images = train_images[:-remainder]\n",
    "    train_labels = train_labels[:-remainder]\n",
    "remainder2 = test_images.shape[0] % BATCH_SIZE\n",
    "if remainder2 != 0:\n",
    "    test_images_q= test_images_q[:-remainder2]\n",
    "    test_images = test_images[:-remainder2]\n",
    "    test_labels = test_labels[:-remainder2]\n",
    "train_images_q.shape, train_labels.shape, test_images_q.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_tensorflow(\"ERROR\")\n",
    "fitting = model.fit(train_images_q, train_labels, epochs=3, batch_size=BATCH_SIZE, validation_data=(test_images_q, test_labels), verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf84bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1574328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/line_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3504614",
   "metadata": {},
   "source": [
    "# A Classical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797c8b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7edea98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m11\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m11\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_22 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> (168.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42\u001b[0m (168.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> (168.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42\u001b[0m (168.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classic_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(N, N, 1)),\n",
    "    tf.keras.layers.Conv2D(2, kernel_size=KERNEL_SIZE, strides=STRIDE, use_bias=True, padding='SAME', activation='selu'),\n",
    "    tf.keras.layers.SeparableConv2D(1, kernel_size=KERNEL_SIZE, strides=STRIDE, use_bias=True, padding='SAME', activation='relu'),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=KERNEL_SIZE),\n",
    "    tf.keras.layers.Conv2D(2, kernel_size=KERNEL_SIZE, strides=STRIDE, use_bias=True, padding='SAME', activation='selu'),\n",
    "    tf.keras.layers.SeparableConv2D(1, kernel_size=KERNEL_SIZE, strides=STRIDE, use_bias=True, padding='SAME', activation='relu'),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=KERNEL_SIZE),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # tf.keras.layers.Dense(8, use_bias=True, activation='relu'),\n",
    "    # tf.keras.layers.Dense(8, use_bias=True, activation='relu'),\n",
    "    # tf.keras.layers.Dense(8, use_bias=True, activation='relu'),\n",
    "    # tf.keras.layers.Dense(1, use_bias=True, activation='sigmoid'),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Activation('sigmoid'),\n",
    "])\n",
    "classic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e81af4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0], dtype=int32)>,\n",
       " TensorShape([80]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic_labels = tf.where(train_labels > 0, 1, 0)\n",
    "classic_test_labels = tf.where(test_labels > 0, 1, 0)\n",
    "# classic_model(train_images[..., np.newaxis])\n",
    "classic_test_labels, classic_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "abce5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_opt = tf.keras.optimizers.Adam(learning_rate=0.025)\n",
    "classic_model.compile(classic_opt, loss=\"CrossEntropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "79ba8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting = classic_model.fit(train_images, classic_labels, epochs=100, batch_size=4, shuffle=True, verbose=0) #, validation_data=(test_images, classic_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbf51f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5938 - loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = classic_model.evaluate(test_images, classic_test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e02f0",
   "metadata": {},
   "source": [
    "# A Better Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0ca461e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_11 (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │            \u001b[38;5;34m20\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │            \u001b[38;5;34m68\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_23 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> (420.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105\u001b[0m (420.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> (420.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105\u001b[0m (420.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classic_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(N, N)),\n",
    "    tf.keras.layers.Reshape((N, N, 1)),\n",
    "    tf.keras.layers.Conv2D(4, kernel_size=2, strides=STRIDE, use_bias=True, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(4, kernel_size=2, strides=STRIDE, use_bias=True, activation='relu'), \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, use_bias=True, activation='sigmoid'),\n",
    "])\n",
    "classic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ca3afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_labels = tf.where(train_labels > 0.0, 1.0, 0.0)\n",
    "classic_test_labels = tf.where(test_labels > 0.0, 1.0, 0.0)\n",
    "# classic_model(train_images[..., np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f797b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_opt = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "classic_model.compile(classic_opt, loss=\"CrossEntropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dcffbef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5174 - loss: 0.6710 - val_accuracy: 0.4688 - val_loss: 0.6910\n",
      "Epoch 2/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5174 - loss: 0.6687 - val_accuracy: 0.4688 - val_loss: 0.6901\n",
      "Epoch 3/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5174 - loss: 0.6665 - val_accuracy: 0.4688 - val_loss: 0.6891\n",
      "Epoch 4/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5174 - loss: 0.6644 - val_accuracy: 0.4688 - val_loss: 0.6879\n",
      "Epoch 5/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5328 - loss: 0.6623 - val_accuracy: 0.4688 - val_loss: 0.6868\n",
      "Epoch 6/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5585 - loss: 0.6601 - val_accuracy: 0.5000 - val_loss: 0.6856\n",
      "Epoch 7/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5998 - loss: 0.6577 - val_accuracy: 0.5312 - val_loss: 0.6844\n",
      "Epoch 8/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6040 - loss: 0.6553 - val_accuracy: 0.5625 - val_loss: 0.6833\n",
      "Epoch 9/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6082 - loss: 0.6529 - val_accuracy: 0.5625 - val_loss: 0.6823\n",
      "Epoch 10/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6082 - loss: 0.6505 - val_accuracy: 0.5625 - val_loss: 0.6811\n",
      "Epoch 11/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6149 - loss: 0.6481 - val_accuracy: 0.5938 - val_loss: 0.6800\n",
      "Epoch 12/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6149 - loss: 0.6457 - val_accuracy: 0.5938 - val_loss: 0.6788\n",
      "Epoch 13/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6149 - loss: 0.6433 - val_accuracy: 0.5938 - val_loss: 0.6776\n",
      "Epoch 14/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6408 - loss: 0.6410 - val_accuracy: 0.5312 - val_loss: 0.6764\n",
      "Epoch 15/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6408 - loss: 0.6386 - val_accuracy: 0.5625 - val_loss: 0.6752\n",
      "Epoch 16/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6667 - loss: 0.6362 - val_accuracy: 0.5625 - val_loss: 0.6740\n",
      "Epoch 17/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6599 - loss: 0.6338 - val_accuracy: 0.5625 - val_loss: 0.6728\n",
      "Epoch 18/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6667 - loss: 0.6313 - val_accuracy: 0.5625 - val_loss: 0.6715\n",
      "Epoch 19/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6769 - loss: 0.6289 - val_accuracy: 0.5625 - val_loss: 0.6703\n",
      "Epoch 20/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6872 - loss: 0.6265 - val_accuracy: 0.5938 - val_loss: 0.6691\n",
      "Epoch 21/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6872 - loss: 0.6240 - val_accuracy: 0.5938 - val_loss: 0.6679\n",
      "Epoch 22/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6872 - loss: 0.6215 - val_accuracy: 0.5938 - val_loss: 0.6666\n",
      "Epoch 23/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7130 - loss: 0.6190 - val_accuracy: 0.5938 - val_loss: 0.6653\n",
      "Epoch 24/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7130 - loss: 0.6165 - val_accuracy: 0.5938 - val_loss: 0.6641\n",
      "Epoch 25/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7130 - loss: 0.6139 - val_accuracy: 0.5938 - val_loss: 0.6628\n",
      "Epoch 26/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7130 - loss: 0.6113 - val_accuracy: 0.5938 - val_loss: 0.6615\n",
      "Epoch 27/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7172 - loss: 0.6087 - val_accuracy: 0.5938 - val_loss: 0.6602\n",
      "Epoch 28/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6967 - loss: 0.6061 - val_accuracy: 0.5938 - val_loss: 0.6589\n",
      "Epoch 29/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6967 - loss: 0.6034 - val_accuracy: 0.5938 - val_loss: 0.6575\n",
      "Epoch 30/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6925 - loss: 0.6007 - val_accuracy: 0.6250 - val_loss: 0.6561\n",
      "Epoch 31/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7122 - loss: 0.5981 - val_accuracy: 0.6250 - val_loss: 0.6547\n",
      "Epoch 32/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7122 - loss: 0.5954 - val_accuracy: 0.6562 - val_loss: 0.6532\n",
      "Epoch 33/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6905 - loss: 0.5927 - val_accuracy: 0.6562 - val_loss: 0.6517\n",
      "Epoch 34/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6750 - loss: 0.5900 - val_accuracy: 0.6562 - val_loss: 0.6502\n",
      "Epoch 35/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6905 - loss: 0.5872 - val_accuracy: 0.6562 - val_loss: 0.6486\n",
      "Epoch 36/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6905 - loss: 0.5845 - val_accuracy: 0.6562 - val_loss: 0.6471\n",
      "Epoch 37/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6905 - loss: 0.5818 - val_accuracy: 0.6562 - val_loss: 0.6455\n",
      "Epoch 38/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6905 - loss: 0.5790 - val_accuracy: 0.6875 - val_loss: 0.6439\n",
      "Epoch 39/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6905 - loss: 0.5763 - val_accuracy: 0.7188 - val_loss: 0.6424\n",
      "Epoch 40/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7007 - loss: 0.5736 - val_accuracy: 0.7500 - val_loss: 0.6409\n",
      "Epoch 41/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7007 - loss: 0.5708 - val_accuracy: 0.7812 - val_loss: 0.6393\n",
      "Epoch 42/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7266 - loss: 0.5681 - val_accuracy: 0.7812 - val_loss: 0.6377\n",
      "Epoch 43/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7401 - loss: 0.5653 - val_accuracy: 0.7812 - val_loss: 0.6362\n",
      "Epoch 44/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7443 - loss: 0.5626 - val_accuracy: 0.7812 - val_loss: 0.6346\n",
      "Epoch 45/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7597 - loss: 0.5598 - val_accuracy: 0.7500 - val_loss: 0.6330\n",
      "Epoch 46/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7597 - loss: 0.5571 - val_accuracy: 0.7188 - val_loss: 0.6314\n",
      "Epoch 47/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7597 - loss: 0.5544 - val_accuracy: 0.7188 - val_loss: 0.6298\n",
      "Epoch 48/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7597 - loss: 0.5517 - val_accuracy: 0.7188 - val_loss: 0.6282\n",
      "Epoch 49/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7597 - loss: 0.5490 - val_accuracy: 0.7188 - val_loss: 0.6266\n",
      "Epoch 50/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7639 - loss: 0.5464 - val_accuracy: 0.7188 - val_loss: 0.6250\n",
      "Epoch 51/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7793 - loss: 0.5437 - val_accuracy: 0.7188 - val_loss: 0.6234\n",
      "Epoch 52/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7793 - loss: 0.5410 - val_accuracy: 0.7188 - val_loss: 0.6219\n",
      "Epoch 53/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7793 - loss: 0.5384 - val_accuracy: 0.7188 - val_loss: 0.6203\n",
      "Epoch 54/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7793 - loss: 0.5357 - val_accuracy: 0.7188 - val_loss: 0.6188\n",
      "Epoch 55/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7793 - loss: 0.5331 - val_accuracy: 0.7188 - val_loss: 0.6172\n",
      "Epoch 56/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7793 - loss: 0.5305 - val_accuracy: 0.7188 - val_loss: 0.6156\n",
      "Epoch 57/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7535 - loss: 0.5280 - val_accuracy: 0.7188 - val_loss: 0.6141\n",
      "Epoch 58/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5254 - val_accuracy: 0.7188 - val_loss: 0.6125\n",
      "Epoch 59/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5229 - val_accuracy: 0.7188 - val_loss: 0.6110\n",
      "Epoch 60/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5203 - val_accuracy: 0.7188 - val_loss: 0.6095\n",
      "Epoch 61/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5178 - val_accuracy: 0.7188 - val_loss: 0.6079\n",
      "Epoch 62/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5153 - val_accuracy: 0.7188 - val_loss: 0.6064\n",
      "Epoch 63/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5128 - val_accuracy: 0.7188 - val_loss: 0.6049\n",
      "Epoch 64/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7602 - loss: 0.5103 - val_accuracy: 0.7188 - val_loss: 0.6033\n",
      "Epoch 65/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5078 - val_accuracy: 0.7188 - val_loss: 0.6018\n",
      "Epoch 66/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7602 - loss: 0.5054 - val_accuracy: 0.7188 - val_loss: 0.6003\n",
      "Epoch 67/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - loss: 0.5029 - val_accuracy: 0.7188 - val_loss: 0.5987\n",
      "Epoch 68/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7670 - loss: 0.5005 - val_accuracy: 0.7188 - val_loss: 0.5972\n",
      "Epoch 69/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7670 - loss: 0.4981 - val_accuracy: 0.7188 - val_loss: 0.5957\n",
      "Epoch 70/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7670 - loss: 0.4958 - val_accuracy: 0.7188 - val_loss: 0.5942\n",
      "Epoch 71/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7670 - loss: 0.4934 - val_accuracy: 0.7188 - val_loss: 0.5927\n",
      "Epoch 72/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7670 - loss: 0.4911 - val_accuracy: 0.7188 - val_loss: 0.5912\n",
      "Epoch 73/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7712 - loss: 0.4887 - val_accuracy: 0.7188 - val_loss: 0.5896\n",
      "Epoch 74/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7712 - loss: 0.4864 - val_accuracy: 0.7188 - val_loss: 0.5881\n",
      "Epoch 75/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7712 - loss: 0.4842 - val_accuracy: 0.7188 - val_loss: 0.5866\n",
      "Epoch 76/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7712 - loss: 0.4820 - val_accuracy: 0.7188 - val_loss: 0.5851\n",
      "Epoch 77/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7712 - loss: 0.4798 - val_accuracy: 0.7188 - val_loss: 0.5837\n",
      "Epoch 78/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7712 - loss: 0.4776 - val_accuracy: 0.7188 - val_loss: 0.5822\n",
      "Epoch 79/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7712 - loss: 0.4755 - val_accuracy: 0.7188 - val_loss: 0.5808\n",
      "Epoch 80/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7712 - loss: 0.4735 - val_accuracy: 0.7188 - val_loss: 0.5793\n",
      "Epoch 81/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4715 - val_accuracy: 0.7188 - val_loss: 0.5779\n",
      "Epoch 82/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7814 - loss: 0.4695 - val_accuracy: 0.7188 - val_loss: 0.5765\n",
      "Epoch 83/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7814 - loss: 0.4675 - val_accuracy: 0.7188 - val_loss: 0.5752\n",
      "Epoch 84/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4656 - val_accuracy: 0.7188 - val_loss: 0.5738\n",
      "Epoch 85/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4637 - val_accuracy: 0.7188 - val_loss: 0.5725\n",
      "Epoch 86/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4618 - val_accuracy: 0.7188 - val_loss: 0.5712\n",
      "Epoch 87/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4600 - val_accuracy: 0.7188 - val_loss: 0.5699\n",
      "Epoch 88/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4582 - val_accuracy: 0.7188 - val_loss: 0.5686\n",
      "Epoch 89/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4564 - val_accuracy: 0.7188 - val_loss: 0.5674\n",
      "Epoch 90/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4546 - val_accuracy: 0.7188 - val_loss: 0.5661\n",
      "Epoch 91/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4529 - val_accuracy: 0.7188 - val_loss: 0.5649\n",
      "Epoch 92/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4512 - val_accuracy: 0.7188 - val_loss: 0.5637\n",
      "Epoch 93/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4496 - val_accuracy: 0.7188 - val_loss: 0.5626\n",
      "Epoch 94/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4481 - val_accuracy: 0.7188 - val_loss: 0.5614\n",
      "Epoch 95/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7814 - loss: 0.4465 - val_accuracy: 0.7188 - val_loss: 0.5603\n",
      "Epoch 96/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4450 - val_accuracy: 0.7188 - val_loss: 0.5592\n",
      "Epoch 97/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4436 - val_accuracy: 0.7188 - val_loss: 0.5581\n",
      "Epoch 98/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4421 - val_accuracy: 0.7188 - val_loss: 0.5570\n",
      "Epoch 99/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4407 - val_accuracy: 0.7188 - val_loss: 0.5559\n",
      "Epoch 100/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4394 - val_accuracy: 0.7188 - val_loss: 0.5549\n",
      "Epoch 101/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4380 - val_accuracy: 0.7188 - val_loss: 0.5539\n",
      "Epoch 102/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4367 - val_accuracy: 0.7500 - val_loss: 0.5529\n",
      "Epoch 103/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4354 - val_accuracy: 0.7812 - val_loss: 0.5519\n",
      "Epoch 104/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4341 - val_accuracy: 0.7812 - val_loss: 0.5509\n",
      "Epoch 105/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7882 - loss: 0.4329 - val_accuracy: 0.7812 - val_loss: 0.5499\n",
      "Epoch 106/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7882 - loss: 0.4316 - val_accuracy: 0.7812 - val_loss: 0.5489\n",
      "Epoch 107/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7882 - loss: 0.4304 - val_accuracy: 0.7812 - val_loss: 0.5480\n",
      "Epoch 108/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7882 - loss: 0.4292 - val_accuracy: 0.7812 - val_loss: 0.5471\n",
      "Epoch 109/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7882 - loss: 0.4280 - val_accuracy: 0.7812 - val_loss: 0.5462\n",
      "Epoch 110/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7882 - loss: 0.4268 - val_accuracy: 0.7812 - val_loss: 0.5453\n",
      "Epoch 111/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7882 - loss: 0.4256 - val_accuracy: 0.7812 - val_loss: 0.5444\n",
      "Epoch 112/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7882 - loss: 0.4245 - val_accuracy: 0.7812 - val_loss: 0.5436\n",
      "Epoch 113/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7882 - loss: 0.4233 - val_accuracy: 0.7812 - val_loss: 0.5428\n",
      "Epoch 114/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8141 - loss: 0.4222 - val_accuracy: 0.7812 - val_loss: 0.5419\n",
      "Epoch 115/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8311 - loss: 0.4211 - val_accuracy: 0.7812 - val_loss: 0.5411\n",
      "Epoch 116/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8311 - loss: 0.4200 - val_accuracy: 0.7812 - val_loss: 0.5403\n",
      "Epoch 117/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8311 - loss: 0.4190 - val_accuracy: 0.7812 - val_loss: 0.5395\n",
      "Epoch 118/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8311 - loss: 0.4179 - val_accuracy: 0.7812 - val_loss: 0.5387\n",
      "Epoch 119/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8311 - loss: 0.4169 - val_accuracy: 0.7812 - val_loss: 0.5380\n",
      "Epoch 120/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8311 - loss: 0.4158 - val_accuracy: 0.8125 - val_loss: 0.5373\n",
      "Epoch 121/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8311 - loss: 0.4148 - val_accuracy: 0.8125 - val_loss: 0.5365\n",
      "Epoch 122/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8352 - loss: 0.4138 - val_accuracy: 0.8125 - val_loss: 0.5357\n",
      "Epoch 123/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8352 - loss: 0.4128 - val_accuracy: 0.8125 - val_loss: 0.5350\n",
      "Epoch 124/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8352 - loss: 0.4118 - val_accuracy: 0.8125 - val_loss: 0.5343\n",
      "Epoch 125/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8352 - loss: 0.4108 - val_accuracy: 0.8125 - val_loss: 0.5336\n",
      "Epoch 126/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8352 - loss: 0.4099 - val_accuracy: 0.8125 - val_loss: 0.5329\n",
      "Epoch 127/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8352 - loss: 0.4089 - val_accuracy: 0.8125 - val_loss: 0.5322\n",
      "Epoch 128/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8352 - loss: 0.4080 - val_accuracy: 0.8125 - val_loss: 0.5314\n",
      "Epoch 129/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8352 - loss: 0.4070 - val_accuracy: 0.8125 - val_loss: 0.5307\n",
      "Epoch 130/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8352 - loss: 0.4061 - val_accuracy: 0.8125 - val_loss: 0.5300\n",
      "Epoch 131/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.4052 - val_accuracy: 0.8125 - val_loss: 0.5293\n",
      "Epoch 132/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.4043 - val_accuracy: 0.8125 - val_loss: 0.5286\n",
      "Epoch 133/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8394 - loss: 0.4034 - val_accuracy: 0.8125 - val_loss: 0.5279\n",
      "Epoch 134/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.4025 - val_accuracy: 0.8125 - val_loss: 0.5273\n",
      "Epoch 135/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.4017 - val_accuracy: 0.8125 - val_loss: 0.5266\n",
      "Epoch 136/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.4008 - val_accuracy: 0.8125 - val_loss: 0.5259\n",
      "Epoch 137/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8394 - loss: 0.3999 - val_accuracy: 0.8125 - val_loss: 0.5253\n",
      "Epoch 138/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3991 - val_accuracy: 0.8125 - val_loss: 0.5246\n",
      "Epoch 139/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3983 - val_accuracy: 0.8125 - val_loss: 0.5240\n",
      "Epoch 140/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.3975 - val_accuracy: 0.8125 - val_loss: 0.5233\n",
      "Epoch 141/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8394 - loss: 0.3967 - val_accuracy: 0.8125 - val_loss: 0.5227\n",
      "Epoch 142/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.3959 - val_accuracy: 0.8125 - val_loss: 0.5221\n",
      "Epoch 143/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.3951 - val_accuracy: 0.8125 - val_loss: 0.5215\n",
      "Epoch 144/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3943 - val_accuracy: 0.8125 - val_loss: 0.5209\n",
      "Epoch 145/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3936 - val_accuracy: 0.8125 - val_loss: 0.5203\n",
      "Epoch 146/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.3928 - val_accuracy: 0.8125 - val_loss: 0.5198\n",
      "Epoch 147/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3920 - val_accuracy: 0.8125 - val_loss: 0.5192\n",
      "Epoch 148/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3913 - val_accuracy: 0.8125 - val_loss: 0.5186\n",
      "Epoch 149/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3905 - val_accuracy: 0.8125 - val_loss: 0.5181\n",
      "Epoch 150/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3898 - val_accuracy: 0.8125 - val_loss: 0.5175\n",
      "Epoch 151/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8394 - loss: 0.3891 - val_accuracy: 0.8125 - val_loss: 0.5169\n",
      "Epoch 152/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3884 - val_accuracy: 0.8125 - val_loss: 0.5164\n",
      "Epoch 153/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3876 - val_accuracy: 0.8125 - val_loss: 0.5158\n",
      "Epoch 154/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3869 - val_accuracy: 0.8125 - val_loss: 0.5152\n",
      "Epoch 155/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3862 - val_accuracy: 0.8125 - val_loss: 0.5146\n",
      "Epoch 156/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3855 - val_accuracy: 0.8125 - val_loss: 0.5141\n",
      "Epoch 157/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3848 - val_accuracy: 0.8125 - val_loss: 0.5135\n",
      "Epoch 158/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3841 - val_accuracy: 0.8125 - val_loss: 0.5129\n",
      "Epoch 159/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3835 - val_accuracy: 0.8125 - val_loss: 0.5124\n",
      "Epoch 160/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3828 - val_accuracy: 0.8125 - val_loss: 0.5118\n",
      "Epoch 161/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8653 - loss: 0.3821 - val_accuracy: 0.8125 - val_loss: 0.5112\n",
      "Epoch 162/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3815 - val_accuracy: 0.8125 - val_loss: 0.5106\n",
      "Epoch 163/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8653 - loss: 0.3808 - val_accuracy: 0.8125 - val_loss: 0.5101\n",
      "Epoch 164/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3801 - val_accuracy: 0.8125 - val_loss: 0.5095\n",
      "Epoch 165/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3795 - val_accuracy: 0.8125 - val_loss: 0.5089\n",
      "Epoch 166/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3788 - val_accuracy: 0.8125 - val_loss: 0.5083\n",
      "Epoch 167/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3781 - val_accuracy: 0.8125 - val_loss: 0.5077\n",
      "Epoch 168/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8653 - loss: 0.3775 - val_accuracy: 0.8125 - val_loss: 0.5071\n",
      "Epoch 169/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3768 - val_accuracy: 0.8125 - val_loss: 0.5065\n",
      "Epoch 170/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3762 - val_accuracy: 0.8125 - val_loss: 0.5059\n",
      "Epoch 171/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3755 - val_accuracy: 0.8125 - val_loss: 0.5053\n",
      "Epoch 172/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8653 - loss: 0.3749 - val_accuracy: 0.8125 - val_loss: 0.5047\n",
      "Epoch 173/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3742 - val_accuracy: 0.8125 - val_loss: 0.5041\n",
      "Epoch 174/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3735 - val_accuracy: 0.8125 - val_loss: 0.5035\n",
      "Epoch 175/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3729 - val_accuracy: 0.8125 - val_loss: 0.5029\n",
      "Epoch 176/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3722 - val_accuracy: 0.8125 - val_loss: 0.5023\n",
      "Epoch 177/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3716 - val_accuracy: 0.8125 - val_loss: 0.5017\n",
      "Epoch 178/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3710 - val_accuracy: 0.8125 - val_loss: 0.5011\n",
      "Epoch 179/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3703 - val_accuracy: 0.8125 - val_loss: 0.5005\n",
      "Epoch 180/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3697 - val_accuracy: 0.8125 - val_loss: 0.4998\n",
      "Epoch 181/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3690 - val_accuracy: 0.8125 - val_loss: 0.4992\n",
      "Epoch 182/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8653 - loss: 0.3684 - val_accuracy: 0.8125 - val_loss: 0.4985\n",
      "Epoch 183/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3677 - val_accuracy: 0.8125 - val_loss: 0.4979\n",
      "Epoch 184/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3671 - val_accuracy: 0.8125 - val_loss: 0.4972\n",
      "Epoch 185/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3664 - val_accuracy: 0.8125 - val_loss: 0.4966\n",
      "Epoch 186/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3658 - val_accuracy: 0.8125 - val_loss: 0.4959\n",
      "Epoch 187/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3651 - val_accuracy: 0.8125 - val_loss: 0.4953\n",
      "Epoch 188/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3645 - val_accuracy: 0.8125 - val_loss: 0.4946\n",
      "Epoch 189/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3638 - val_accuracy: 0.8125 - val_loss: 0.4939\n",
      "Epoch 190/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3632 - val_accuracy: 0.8125 - val_loss: 0.4933\n",
      "Epoch 191/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8653 - loss: 0.3625 - val_accuracy: 0.8125 - val_loss: 0.4926\n",
      "Epoch 192/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3618 - val_accuracy: 0.8125 - val_loss: 0.4920\n",
      "Epoch 193/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3612 - val_accuracy: 0.8125 - val_loss: 0.4913\n",
      "Epoch 194/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.3605 - val_accuracy: 0.8125 - val_loss: 0.4907\n",
      "Epoch 195/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8653 - loss: 0.3599 - val_accuracy: 0.8125 - val_loss: 0.4900\n",
      "Epoch 196/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8911 - loss: 0.3592 - val_accuracy: 0.8125 - val_loss: 0.4893\n",
      "Epoch 197/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8911 - loss: 0.3586 - val_accuracy: 0.8125 - val_loss: 0.4887\n",
      "Epoch 198/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8911 - loss: 0.3579 - val_accuracy: 0.8125 - val_loss: 0.4880\n",
      "Epoch 199/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8911 - loss: 0.3573 - val_accuracy: 0.8125 - val_loss: 0.4874\n",
      "Epoch 200/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8911 - loss: 0.3567 - val_accuracy: 0.8125 - val_loss: 0.4867\n"
     ]
    }
   ],
   "source": [
    "fitting = classic_model.fit(train_images, classic_labels, epochs=200, batch_size=16, shuffle=True, validation_data=(test_images, classic_test_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e4cf2f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8125 - loss: 0.4867\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = classic_model.evaluate(test_images, classic_test_labels, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

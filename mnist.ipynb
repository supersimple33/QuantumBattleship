{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d495a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import importlib\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import numpy as nnp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "# tf.keras.backend.set_floatx('bfloat32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1af02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import traceback\n",
    "\n",
    "warnings.simplefilter(\"error\")\n",
    "warnings.simplefilter(\"once\", category=qml.PennyLaneDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab1d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "# torch.manual_seed(42)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c74b30",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334f9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_4(num_images: int, size: int = 4, noise: float = 0.15):\n",
    "    \"\"\"Generate a vertical horizontal left diagonal or right diagonal line on the grid and then add noise in to it\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        # Create a blank image\n",
    "        image = np.zeros((size, size), dtype=np.uint16)\n",
    "        # Randomly choose a line orientation\n",
    "        if np.random.rand() < 0.25:\n",
    "            # Vertical line\n",
    "            x = np.random.randint(0, size)\n",
    "            image[:, x] = 255\n",
    "            labels.append(0)  # Label for vertical line\n",
    "        elif np.random.rand() < 0.5:\n",
    "            # Horizontal line\n",
    "            y = np.random.randint(0, size)\n",
    "            image[y, :] = 255\n",
    "            labels.append(1)\n",
    "        elif np.random.rand() < 0.75:\n",
    "            # Left diagonal line\n",
    "            for j in range(size):\n",
    "                image[j, j] = 255\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            # Right diagonal line\n",
    "            for j in range(size):\n",
    "                image[j, size - j - 1] = 255\n",
    "            labels.append(3)\n",
    "\n",
    "        # Add noise to the image\n",
    "        noise_matrix = np.random.normal(0, noise * 255, (size, size))\n",
    "        image = np.clip(image + noise_matrix, 0.0, 255.0)\n",
    "        images.append(image.astype(np.float32) / 255.0)\n",
    "\n",
    "    # one hot encode the labels\n",
    "    labels = np.array(labels)\n",
    "    labels = np.eye(4)[labels]\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def generate_dataset_2(num_images: int, size: int = 4, noise: float = 0.15):\n",
    "    \"\"\"Generate a vertical or horizontal line on the grid and then add noise in to it\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        # Create a blank image\n",
    "        image = np.zeros((size, size), dtype=np.uint16)\n",
    "        # Randomly choose a line orientation\n",
    "        if np.random.rand() < 0.5:\n",
    "            # Vertical line\n",
    "            x = np.random.randint(0, size)\n",
    "            image[:, x] = 255\n",
    "            labels.append(-1.0)  # Label for vertical line\n",
    "        else:\n",
    "            # Horizontal line\n",
    "            y = np.random.randint(0, size)\n",
    "            image[y, :] = 255\n",
    "            labels.append(1.0)\n",
    "\n",
    "        # Add noise to the image\n",
    "        noise_matrix = np.random.normal(0, noise * 255, (size, size))\n",
    "        image = np.clip(image + noise_matrix, 0.0, 255.0)\n",
    "        images.append(image.astype(np.float32) / 255.0)\n",
    "\n",
    "    # one hot encode the labels\n",
    "    # labels = np.array(labels)\n",
    "    # labels = np.eye(2)[labels]\n",
    "    return np.array(images), np.array(labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43399685",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = generate_dataset_2(150, noise=0.05)\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "# conver them to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f9a199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(train_images[i].reshape(train_images.shape[1], train_images.shape[2]), cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010162bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:20:35.901186: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-05-15 21:20:35.901221: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2025-05-15 21:20:35.901251: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747358435.901277 1559316 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1747358435.901334 1559316 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = tf.convert_to_tensor(train_images), tf.convert_to_tensor(train_labels)\n",
    "test_images, test_labels = tf.convert_to_tensor(test_images), tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6e2eb",
   "metadata": {},
   "source": [
    "# Creating Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ac6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_images.shape[1] == train_images.shape[2], \"Images must be square\"\n",
    "N = train_images.shape[1]\n",
    "B = 4\n",
    "dev = qml.device(\"default.qubit\", wires=N * N + B)\n",
    "wire_arr = nnp.arange(N * N).reshape(N, N)\n",
    "\n",
    "KERNEL_SIZE = 2\n",
    "KERNEL_LAYERS = 2\n",
    "STRIDE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24c6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def qnode(inputs, \n",
    "          first_kernel, first_pooling, \n",
    "          second_kernel, second_pooling, \n",
    "          # fc_weights, fc_bias\n",
    "):\n",
    "    # Input Layer\n",
    "    for i, j in itertools.product(range(N), range(N)):\n",
    "        qml.RX(1.0 * np.pi * inputs[i, j], wires=wire_arr[i, j])\n",
    "    \n",
    "    # First Convolution Layer    \n",
    "    convolution_pooling_op(first_kernel, first_pooling, wire_arr, STRIDE)\n",
    "    reduced_wire_arr = wire_arr[1::2, 1::2]\n",
    "    \n",
    "    # Second Convolution Layer\n",
    "    convolution_pooling_op(second_kernel, second_pooling, reduced_wire_arr, STRIDE)\n",
    "    reduced_wire_arr = reduced_wire_arr[1::2, 1::2]\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    # fully_connected_op(fc_weights, fc_bias, reduced_wire_arr.flatten().tolist(), list(range(N*N, N*N + B)))\n",
    "    \n",
    "    # Measurement\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in reduced_wire_arr.flatten().tolist()]\n",
    "    # return [qml.probs(i) for i in reduced_wire_arr.flatten().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876abf89",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonhanrattie/Downloads/QuantumBattleship.nosync/.conda/lib/python3.10/site-packages/pennylane/qnn/keras.py:317: PennyLaneDeprecationWarning: The 'KerasLayer' class is deprecated and will be removed in v0.42. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'first_kernel': (8, TensorShape([2, 2, 2])),\n",
       "  'first_pooling': (4, TensorShape([2, 2])),\n",
       "  'second_kernel': (8, TensorShape([2, 2, 2])),\n",
       "  'second_pooling': (4, TensorShape([2, 2]))},\n",
       " <Quantum Keras Layer: func=qnode>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_shapes = {\n",
    "    \"first_kernel\": (KERNEL_LAYERS, KERNEL_SIZE, KERNEL_SIZE),\n",
    "    \"first_pooling\": (KERNEL_SIZE, KERNEL_SIZE),\n",
    "    \"second_kernel\": (KERNEL_LAYERS, KERNEL_SIZE, KERNEL_SIZE),\n",
    "    \"second_pooling\": (KERNEL_SIZE, KERNEL_SIZE),\n",
    "    # \"fc_weights\": (B - 1, B),\n",
    "    # \"fc_bias\": (B,),\n",
    "}\n",
    "\n",
    "qlayer = PatchedKerasLayer(qnode, weight_shapes, output_dim=(1,))\n",
    "{name: (reduce(operator.mul, x.shape), x.shape) for name, x in qlayer.qnode_weights.items()}, qlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60176fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(N, N)),\n",
    "    qlayer,\n",
    "    # tf.keras.layers.Lambda(prob_extraction),\n",
    "])\n",
    "# model.load_weights('line_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f558566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ patched_keras_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchedKerasLayer</span>)             │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ patched_keras_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m24\u001b[0m │\n",
       "│ (\u001b[38;5;33mPatchedKerasLayer\u001b[0m)             │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.025)\n",
    "model.compile(opt, loss=\"MSE\", metrics=[custom_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b06efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output shape: (1, 5)\n",
      "Sample output: [[ 0.02729531 -0.10849536  0.02598418 -0.06261391 -0.10627695]] tf.Tensor([ 1. -1.  1. -1. -1.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test the forward pass with a batch of training images\n",
    "sample_output = model(train_images[:5])  # Pass the first 3 training images\n",
    "print(\"Sample output shape:\", sample_output.shape)\n",
    "print(\"Sample output:\", sample_output.numpy(), train_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4e01b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c4a426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 4s/step - custom_accuracy: 0.7702 - loss: 0.9731 - val_custom_accuracy: 0.9111 - val_loss: 0.8753\n",
      "Epoch 2/4\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 4s/step - custom_accuracy: 0.9535 - loss: 0.8497 - val_custom_accuracy: 1.0000 - val_loss: 0.8183\n",
      "Epoch 3/4\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4s/step - custom_accuracy: 1.0000 - loss: 0.8037 - val_custom_accuracy: 1.0000 - val_loss: 0.7949\n",
      "Epoch 4/4\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4s/step - custom_accuracy: 1.0000 - loss: 0.7826 - val_custom_accuracy: 1.0000 - val_loss: 0.7918\n"
     ]
    }
   ],
   "source": [
    "silence_tensorflow(\"ERROR\")\n",
    "fitting = model.fit(train_images, train_labels, epochs=4, batch_size=16, validation_data=(test_images, test_labels), verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf84bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.11613654, -0.13755006],\n",
       "        [ 0.0724539 , -0.790224  ]],\n",
       "\n",
       "       [[ 0.16803056,  0.6093633 ],\n",
       "        [-0.59715074,  0.11533863]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1574328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/line_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
